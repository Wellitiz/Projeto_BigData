{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tratamento e lmpeza do dados**\n",
    "\n",
    "Iniciando as atividades de tratamento do DF importamos as bibliotecas pandas e numpy, através delas poderemos utilizar comandos que facilitarão a limpeza dos dados e organização do DF para posteriormente iniciar as análises. \n",
    "\n",
    "* Neste mesmo dataframe de importação das bilbiotecas criamos uma variável chamada **'df'**, ela contém na memória o arquivo CSV e quando necessitamos referenciar o arquivo utilizamos a nomenclatura da variável(**'df'**) juntamente com os scripts das bilbiotecas para executar as ações no DF e assim realizar as operações necessárias.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Frame**\n",
    "Um DataFrame é uma estrutura de dados bidimensional tabular no pandas, uma biblioteca de análise de dados em Python. É uma das principais estruturas de dados oferecidas pelo pandas e é semelhante a uma planilha ou a uma tabela de banco de dados SQL. O pandas é uma biblioteca amplamente utilizada para manipulação e análise de dados em Python, e o DataFrame é uma de suas principais ferramentas para lidar com dados tabulares.\n",
    "\n",
    "#### **1. Bidimensional:** \n",
    "* O DataFrame é uma estrutura bidimensional, organizada em linhas e colunas. Cada linha representa uma observação, enquanto cada coluna representa uma variável ou um atributo específico.\n",
    "\n",
    "#### **2. Rótulos de Linhas e Colunas:** \n",
    "* Os DataFrames possuem rótulos para linhas e colunas. Os rótulos de colunas são os nomes das variáveis, e os rótulos de linhas são os índices das observações.\n",
    "\n",
    "#### **3. Flexibilidade de Dados:** \n",
    "* Cada coluna em um DataFrame pode conter dados de tipos diferentes, como inteiros, floats, strings, datas, etc.\n",
    "\n",
    "#### **4. Funcionalidades de Indexação e Seleção:** \n",
    "* Os DataFrames oferecem métodos poderosos para indexar e selecionar dados com base em critérios específicos.\n",
    "\n",
    "#### **5. Manipulação e Transformação de Dados:** \n",
    "* O pandas fornece uma ampla variedade de funções para manipulação e transformação de dados, incluindo operações de agregação, filtragem, ordenação, junção, entre outras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instalação e Importação de bibliotecas**\n",
    "\n",
    "* **openpyxl:** É uma biblioteca Python que permite a leitura e escrita de arquivos Excel (xlsx). Com o openpyxl, você pode manipular planilhas, células e formatos Excel em seu código Python.\n",
    "\n",
    "* **xlwt:** Essa biblioteca é usada para criar arquivos Excel no formato antigo (.xls). Note que ela é mais antiga e menos flexível do que o openpyxl e geralmente é usada quando você precisa lidar com formatos de arquivo mais antigos.\n",
    "\n",
    "* **import pandas as pd:** Importa a biblioteca Pandas e a renomeia como pd. O Pandas é amplamente utilizado para manipulação e análise de dados em Python, fornecendo estruturas de dados flexíveis chamadas DataFrames.\n",
    "\n",
    "* **import numpy as np:** Importa a biblioteca NumPy e a renomeia como np. O NumPy é usado para operações numéricas eficientes em Python, especialmente quando se lida com arrays e matrizes.\n",
    "\n",
    "* **from unidecode import unidecode:** Importa a função unidecode do módulo unidecode. Essa função é utilizada para remover acentuações e converter caracteres especiais em suas formas não acentuadas. É útil para normalizar texto, especialmente ao lidar com dados que podem conter caracteres acentuados.\n",
    "\n",
    "* **import matplotlib.pyplot as plt:** Importa o módulo pyplot da biblioteca Matplotlib e o renomeia como plt. A Matplotlib é uma biblioteca de visualização de dados em Python, e o módulo pyplot fornece funções para criar gráficos e visualizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n",
    "!pip install xlwt\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Geolocation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomeando caminho\n",
    "csv_olist_geolocation_dataset = \"./Files/Dataset/olist_geolocation_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_geolocation_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Função para remover acentos e caracteres especiais**\n",
    "Essa função e o trecho de código associado têm o objetivo de padronizar as cidades em um DataFrame pandas, removendo acentuações e caracteres especiais. Vamos explicar cada parte:\n",
    "\n",
    "**Função padronizar_cidade(city):**\n",
    "\n",
    "* **unidecode(city):** Utiliza a biblioteca unidecode para remover a acentuação do texto da cidade. Por exemplo, converte caracteres acentuados como \"á\" para \"a\".\n",
    "\n",
    "* **''.join(e for e in city_sem_acentos if e.isalnum() or e.isspace()):** Itera pelos caracteres do texto após remover a acentuação (city_sem_acentos). Para cada caractere, verifica se é alfanumérico (e.isalnum()) ou se é um espaço em branco (e.isspace()). Se atender a essas condições, o caractere é mantido. Isso resulta em uma string que contém apenas caracteres alfanuméricos e espaços.\n",
    "\n",
    "* **Retorna a cidade padronizada.**\n",
    "\n",
    "* **Aplicação da função ao DataFrame:**\n",
    "\n",
    "* **df.geo['geolocation_city'].apply(padronizar_cidade):** Aplica a função padronizar_cidade a cada valor na coluna 'geolocation_city' do DataFrame df.geo e cria uma nova coluna chamada 'geolocation_city_padronizada' que contém as cidades padronizadas.\n",
    "\n",
    "* **df.geo[['geolocation_city', 'geolocation_city_padronizada']]:** Exibe no console as colunas 'geolocation_city' e 'geolocation_city_padronizada' do DataFrame resultante.\n",
    "\n",
    "Resumindo, a função e o trecho de código têm como objetivo criar uma versão padronizada das cidades removendo acentuações e caracteres especiais, o que pode ser útil para normalizar os dados e facilitar a análise ou comparação de informações geográficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover acentuações e caracteres especiais\n",
    "def padronizar_cidade(city):\n",
    "    city_sem_acentos = unidecode(city)\n",
    "    city_sem_especiais = ''.join(e for e in city_sem_acentos if e.isalnum() or e.isspace())\n",
    "    return city_sem_especiais\n",
    "\n",
    "# Aplica a função à coluna 'geolocation_city'\n",
    "df['geolocation_city_padronizada'] = df['geolocation_city'].apply(padronizar_cidade)\n",
    "\n",
    "# Exibe o DataFrame resultante\n",
    "print(df[['geolocation_city', 'geolocation_city_padronizada']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores unicos\n",
    "O código **df.geo['geolocation_city_padronizada'].unique()** é usado para obter os valores únicos na coluna 'geolocation_city_padronizada' de um DataFrame pandas (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geolocation_city_padronizada'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reescrevendo nomes de cidades relevantes**\n",
    "Notamos que algumas cidades tem os nomes repetidos mas escruitos de formas diferetes.\n",
    "Usamos o codigo a seguir para substituir os valores mais relevanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geolocation_city_padronizada'] = df['geolocation_city_padronizada'].replace(['saopaulo', 'saPSo paulo' ], 'sao paulo')\n",
    "df['geolocation_city_padronizada'] = df['geolocation_city_padronizada'].replace(['4o centenario'], 'quarto centenario')\n",
    "df['geolocation_city_padronizada'] = df['geolocation_city_padronizada'].replace(['floripa'], 'florianopolis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecione a coluna desejada\n",
    "unique_cities = df['geolocation_city_padronizada'].unique()\n",
    "\n",
    "# Crie um DataFrame a partir do array\n",
    "df_unique_cities = pd.DataFrame({'Unique Cities': unique_cities})\n",
    "\n",
    "# Exiba o DataFrame\n",
    "df_unique_cities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ranking das Cidades**\n",
    "\n",
    "Abaixo estão as cinco cidades com maior frequência no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['geolocation_city_padronizada']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data frame com os dados Tratados**\n",
    "\n",
    "Foi criado uma nova coluna (*geolocation_city_padronizada*) com os nomes das cidades sem acentos e caracteres especiais.\n",
    "\n",
    "A partir daqui o Data Frame foi renomeado para **_df_geolocation_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas: geolocation_zip_code_prefix\tgeolocation_lat\tgeolocation_lng\tgeolocation_city\tgeolocation_state\n",
    "df_geolocation = df[['geolocation_zip_code_prefix','geolocation_city_padronizada','geolocation_state']]\n",
    "df_geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**\n",
    "Para facilitar as analises o resultado foi exportado em formato CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_geolocation'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_geolocation.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DatFrame Payments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_order_payments_dataset = \"./Files/Dataset/olist_order_payments_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_order_payments_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Descrição dos dados**\n",
    "Descrição dos dados com total de linhas, número de colunas, tipo de cada série e se há valores nulos. (**Não há valores nulos**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_order_payments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_payments = df\n",
    "df_order_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_order_payments'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_order_payments.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_payments['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Orders Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_orders_dataset = \"./Files/Dataset/olist_orders_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_orders_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploração de valores nulos**\n",
    "\n",
    "Fora identificados valores nulos nas colunas conforme descrito abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remoção de Valores Nulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoção de valores nulos\n",
    "df = df.dropna(subset=['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado após a remoção dos valores nulos. \n",
    "Conforme o resultado abaixo, foram removidos os valores nulos, facilitando a **análise sobre pedidos aprovados e entregues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Processando uma lista de colunas**\n",
    "\n",
    "**colunas_para_processar**Esta linha cria uma lista chamada colunas_para_processar, que contém os nomes das colunas que serão processadas.\n",
    "Iteração sobre as Colunas e Realização da Separação:\n",
    "\n",
    "**for coluna in colunas_para_processar:** Este trecho usa um loop for para iterar sobre cada coluna especificada na lista colunas_para_processar.\n",
    "\n",
    "**df[coluna].str.split(' ', expand=True):** Divide cada valor na coluna atual (coluna) usando o espaço como delimitador e expande o resultado em um DataFrame com duas colunas (uma para data e outra para hora).\n",
    "\n",
    "**novas_colunas.columns = [f\"{coluna}_date\", f\"{coluna}_hour\"]:** Renomeia as colunas do DataFrame resultante para incluir o nome da coluna original e distinguir entre data e hora.\n",
    "\n",
    "**pd.concat([df, novas_colunas], axis=1):** Concatena horizontalmente o DataFrame original (df) com o DataFrame contendo as novas colunas, adicionando assim essas novas colunas ao DataFrame original.\n",
    "\n",
    "Ao final do loop, o DataFrame df foi expandido com novas colunas para cada coluna original especificada na lista colunas_para_processar. Cada coluna original foi dividida em duas novas colunas: uma para data e outra para hora. Essa operação é útil quando as colunas originais contêm informações combinadas de data e hora e é necessário analisar ou manipular esses componentes separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas a serem processadas\n",
    "colunas_para_processar = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "# Iterando sobre as colunas e realizando a separação\n",
    "for coluna in colunas_para_processar:\n",
    "    # Criando novas colunas\n",
    "    novas_colunas = df[coluna].str.split(' ', expand=True)\n",
    "    \n",
    "    # Nomeando as novas colunas\n",
    "    novas_colunas.columns = [f\"{coluna}_date\", f\"{coluna}_hour\"]\n",
    "    \n",
    "    # Adicionando as novas colunas ao DataFrame original\n",
    "    df = pd.concat([df, novas_colunas], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Removendo Colunas**\n",
    "Este trecho de código está removendo colunas específicas do DataFrame df. Aqui está uma explicação passo a passo:\n",
    "\n",
    "* **colunas_para_remover:** Nessa linha, uma lista chamada colunas_para_remover é criada, contendo os nomes das colunas que você deseja remover do DataFrame.\n",
    "* **df = df.drop(columns=colunas_para_remover):** Aqui, o método drop é utilizado no DataFrame df para remover as colunas especificadas na lista colunas_para_remover. O argumento columns é usado para indicar quais colunas devem ser removidas.\n",
    "\n",
    "O resultado da operação é atribuído novamente à variável df, ou seja, o DataFrame original é modificado para refletir as colunas removidas.\n",
    "\n",
    "Com isso, o DataFrame df não terá mais as colunas listadas em colunas_para_remover. Essa abordagem é útil quando você deseja eliminar colunas que não são relevantes ou necessárias para a análise que está realizando.\n",
    "\n",
    "Se precisar de mais esclarecimentos ou tiver outras perguntas, sinta-se à vontade para perguntar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas a serem removidas\n",
    "colunas_para_remover = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "# Removendo as colunas\n",
    "df = df.drop(columns=colunas_para_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_order_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_dataset = df\n",
    "df_order_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_order_dataset'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_order_dataset.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_products_dataset = \"./Files/Dataset/olist_products_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_products_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Composição de Tipos de Dados no Dataset**\n",
    "\n",
    "O script abaixo exibe através do comando .dtypes a composição das colunas onde \"objects\" são strings e \"float64\" trata-se de números de pontos flutuantes ou com casas decimais após a vírgula. As colunas compostas por \"float64\" podem ser tratadas com operadores matemáticos no momento da análise exploratória, por tanto, caso alguma coluna contendo números que necessitarão sofrer operações nas análises não esteja no formato \"float64\" será necessário a conversão para este formato para a efetividade das análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando\n",
    "* **dts.shape:** Exibe o total de linhas e colunas presentes no DF utilizando o comando \".shape\" ,  neste caso podemos observar que ele é composto por 32951 linhas e 9 colunas\n",
    "* **dts.columns:** Exibe o nome das colunas presentes no arquivo. Através do nome das colunas poderemos elaborar scripts especificando quais colunas serão tratadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_products_dataset.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products_dataset = df\n",
    "df_products_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_products_dataset'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_products_dataset.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Category Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_product_category_name_translation = \"./Files/Dataset/product_category_name_translation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_product_category_name_translation)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verificação**\n",
    "\n",
    "O Codigo abaixo serve para verificar se a dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_category_names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_names = df\n",
    "df_category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_category_names'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_category_names.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Sellers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_sellers_dataset = \"./Files/Dataset/olist_sellers_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_sellers_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Resultados obtidos sem a tratativa de padronização no nome da cidade de sao paulo que possui a maior variação de formas escritas dentro do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Padronização de escrita**\n",
    "\n",
    "Este trecho de código tem o objetivo de padronizar diferentes formas de escrever \"São Paulo\" na coluna 'seller_city' de um DataFrame chamado df. Vamos explicar cada parte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as diferentes formas de escrever \"Sao Paulo\"\n",
    "diferentes_formas_sao_paulo = ['Sao Paulo', 'São Paulo', 'são paulo', 'SAO PAULO', 'SÃO PAULO', 'sao pulo', 'sp - sp', 'sao paulo - sp', \n",
    "                               'sao paulo / sao paulo', 'sao paulop', 'sao paluo', 'sao paulo sp' ]\n",
    "\n",
    "# Cria uma condição booleana para identificar as linhas que atendem ao critério\n",
    "condicao = df['seller_city'].str.lower().isin(diferentes_formas_sao_paulo)\n",
    "\n",
    "# Substitui os valores na coluna 'seller_city' onde a condição é verdadeira\n",
    "df.loc[condicao, 'seller_city'] = 'sao paulo'\n",
    "\n",
    "# Exibe o DataFrame atualizado\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_sellers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sellers = df\n",
    "df_sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_sellers'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_sellers.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DatFrame Customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_customers_dataset = \"./Files/Dataset/olist_customers_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_customers_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esta função oferece uma visão geral da estrutura do DataFrame, incluindo detalhes sobre os tipos de dados de cada coluna, a contagem de valores não nulos em cada coluna e a quantidade de memória utilizada pelo DataFrame. É uma maneira rápida e útil de entender a composição do DataFrame, identificar valores ausentes e compreender a distribuição de dados antes de realizar análises mais detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe clientes\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df.describe(include=object)' apresenta estatísticas descritivas das colunas não numéricas do DataFrame 'df_clientes', incluindo contagem, quantidade de valores únicos, valor mais frequente e sua frequência. Essas estatísticas oferecem uma visão geral dos dados textuais presentes nessas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta os tipos de dados\n",
    "\n",
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df['customer_city'].value_counts()' conta e retorna a frequência de ocorrência de valores únicos na coluna 'customer_city' do DataFrame 'df_clientes'. Isso oferece insights sobre a distribuição das cidades dos clientes na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contabiliza e retorna os as ocorrencias na coluna\n",
    "\n",
    "df['customer_city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* O código cria um novo DataFrame chamado 'clientes' a partir do DataFrame 'df_clientes', incluindo apenas as colunas especificadas ('customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state'). Isso simplifica o DataFrame para conter apenas informações relevantes para análise ou manipulação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de definição de colunas\n",
    "\n",
    "clientes = df.filter(items=['customer_id', 'customer_unique_id', 'customer_zip_code_prefix',\n",
    "       'customer_city', 'customer_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df_clientes.columns.values' retorna os nomes das colunas presentes no DataFrame 'df_clientes' como um array NumPy. Isso é útil para obter uma lista rápida dos nomes das colunas no DataFrame para referência ou manipulação direta das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de colunas\n",
    "\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código cria um novo DataFrame chamado 'df_clientes' a partir do DataFrame 'clientes', incluindo apenas as colunas especificadas ('customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state'). Essa ação simplifica o DataFrame, mantendo apenas as informações relevantes para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de definição de colunas\n",
    "\n",
    "df_clientes= clientes.filter(items=['customer_id', 'customer_unique_id', 'customer_zip_code_prefix',\n",
    "       'customer_city', 'customer_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* O código substitui células vazias por NaN no DataFrame 'clientes', remove as linhas com valores nulos criando o DataFrame 'clientes_sem_celulas_vazias', exibe a contagem de valores não nulos após a remoção e calcula a diferença na contagem de valores não nulos antes e depois da limpeza para identificar a quantidade de valores nulos removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir células vazias por NaN\n",
    "\n",
    "clientes_sem_celulas_vazias = df.replace(\"\", pd.NA)\n",
    "\n",
    "# Remover linhas com células vazias\n",
    "\n",
    "clientes_sem_celulas_vazias = clientes_sem_celulas_vazias.dropna()\n",
    "\n",
    "# Mostrar a contagem de valores não nulos após a remoção\n",
    "\n",
    "print(\"\\nValores não nulos APÓS a remoção:\")\n",
    "print(clientes_sem_celulas_vazias.count())\n",
    "\n",
    "# Comparar a diferença na contagem de valores não nulos\n",
    "\n",
    "diferenca = clientes.count() - clientes_sem_celulas_vazias.count()\n",
    "print(\"\\nDiferença na contagem de valores não nulos:\")\n",
    "print(diferenca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_clientes\n",
    "df_customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_customers'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_customers.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Order Items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_order_items_dataset = \"./Files/Dataset/olist_order_items_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_order_items_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'df.info()' fornece um resumo breve e essencial do DataFrame unidades, incluindo o número de linhas, os nomes das colunas, os tipos de dados em cada coluna e a contagem de valores não nulos. Essa função é fundamental para obter uma visão geral da estrutura e qualidade dos dados antes de realizar análises mais detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe clientes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código df.describe(include=object) fornece um resumo estatístico das colunas não numéricas (do tipo 'object') no DataFrame unidades, incluindo contagem, quantidade de valores únicos, valor mais frequente e sua respectiva frequência. Isso é útil para entender a natureza e a diversidade dos dados textuais presentes nessas colunas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta os tipos de dados\n",
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O comando 'df.columns.values' retorna os nomes das colunas presentes no DataFrame 'unidades' como um array NumPy. Essa ação é útil para obter rapidamente uma lista dos nomes das colunas para referência ou manipulação específica das colunas no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de colunas\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df['price'].value_counts()' em Python, usando o Pandas, conta a frequência dos valores únicos presentes na coluna 'price' do DataFrame 'unidades'. Isso proporciona uma visão da distribuição dos valores de preço e suas frequências no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contabiliza e retorna os as ocorrencias na coluna\n",
    "df['price'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df.columns.values' em Python, utilizando Pandas, retorna os nomes das colunas presentes no DataFrame 'unidades' como um array NumPy. Essa ação é útil para obter uma lista dos nomes das colunas e utilizá-la em operações de referência ou manipulação específica das colunas no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de colunas\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df = df.filter(items=[...])' seleciona e recria o DataFrame 'unidades' incluindo apenas as colunas especificadas ('order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value'). Isso ajuda a focar a análise nos dados relevantes contidos nessas colunas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de definição de colunas\n",
    "df = df.filter(items=['order_id', 'order_item_id', 'product_id',\n",
    "       'seller_id', 'shipping_limit_date', 'price', 'freight_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código remove células vazias do DataFrame 'df' substituindo-as por NaN, em seguida, elimina as linhas com valores nulos criando o DataFrame 'unidades_sem_celulas_vazias'. Posteriormente, exibe a contagem de valores não nulos após a remoção e calcula a diferença na contagem de valores não nulos antes e depois da remoção para identificar a quantidade de valores nulos removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir células vazias por NaN\n",
    "unidades_sem_celulas_vazias = df.replace(\"\", pd.NA)\n",
    "\n",
    "# Remover linhas com células vazias\n",
    "unidades_sem_celulas_vazias = unidades_sem_celulas_vazias.dropna()\n",
    "\n",
    "# Mostrar a contagem de valores não nulos após a remoção\n",
    "print(\"\\nValores não nulos APÓS a remoção:\")\n",
    "print(unidades_sem_celulas_vazias.count())\n",
    "\n",
    "# Comparar a diferença na contagem de valores não nulos\n",
    "diferenca = df.count() - unidades_sem_celulas_vazias.count()\n",
    "print(\"\\nDiferença na contagem de valores não nulos:\")\n",
    "print(diferenca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_order_itens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_itens = df\n",
    "df_order_itens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_order_itens'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_order_itens.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataFrame Order Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomeando Caminho\n",
    "csv_olist_order_reviews_dataset = \"./Files/Dataset/olist_order_reviews_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df = pd.read_csv(csv_olist_order_reviews_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Seguindo os mesmos principios dos DataFrames anteriores realizamos as analises a seguir.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe clientes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta os tipos de dados\n",
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de colunas\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código divide a coluna 'review_creation_date' do DataFrame 'df' em duas colunas separadas ('review_creation_date' e 'review_creation_hour') utilizando o espaço como delimitador. O DataFrame 'df_avaliacoes' é atualizado com as novas colunas adicionadas pela operação split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de duas novas colunas\n",
    "df[['review_creation_date', 'review_creation_hour']] = df['review_creation_date'].str.split(' ', expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código divide a coluna 'review_answer_timestamp' do DataFrame 'df' em duas novas colunas ('review_answer_date' e 'review_answer_hour') utilizando o espaço como delimitador. Em seguida, essas novas colunas são adicionadas ao DataFrame 'df_avaliacoes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de duas novas colunas\n",
    "\n",
    "df[['review_answer_date', 'review_answer_hour']] = df['review_answer_timestamp'].str.split(' ', expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código remove a coluna 'review_answer_timestamp' do DataFrame 'df', especificando o eixo como colunas (axis=1), mas não atualiza o DataFrame original. É necessário atribuir o resultado a uma variável para aplicar a remoção permanentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de coluna\n",
    "df.drop('review_answer_timestamp', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código 'df_avaliacoes.columns.values' retorna os nomes das colunas do DataFrame 'df' como um array NumPy. A chamada 'df_avaliacoes' exibe o conteúdo do DataFrame, mostrando as novas colunas criadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização após a criação das novas colunas\n",
    "df.columns.values\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conferindo as colunas\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código seleciona a coluna 'review_comment_title' do DataFrame 'df' e utiliza o método 'value_counts()' para contar a frequência dos diferentes valores presentes nessa coluna. A opção 'dropna=False' mantém a contagem dos valores ausentes (NaN) e 'value_counts' mostra a contagem de cada valor na coluna 'review_comment_title'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conferindo valores\n",
    "columns_to_count = ['review_comment_title']\n",
    "\n",
    "value_counts = df[columns_to_count].value_counts(dropna=False)\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código conta a frequência de ocorrência dos números na coluna 'review_comment_message' do DataFrame 'df'. Ele utiliza 'value_counts()' para mostrar a contagem de cada número presente nessa coluna, incluindo valores ausentes (NaN), e exibe os resultados com 'print(value_counts)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de numeros\n",
    "\n",
    "columns_to_count = ['review_comment_message']\n",
    "\n",
    "value_counts = df[columns_to_count].value_counts(dropna=False)\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O código cria um novo DataFrame chamado 'df', selecionando apenas colunas específicas ('order_id', 'order_item_id', 'product_id', 'seller_id', 'price', 'freight_value', 'date_id', 'time_id') do DataFrame 'df_avaliacoes'. Essa ação foca em informações específicas para análise ou manipulação adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um novo dataframe\n",
    "\n",
    "df = df.filter(items=['order_id', 'order_item_id', 'product_id', 'seller_id', 'price',\n",
    "       'freight_value', 'date_id', 'time_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A partir daqui o Data Frame foi renomeado para df_order_reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_reviews = df\n",
    "df_order_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando para um arquivo .csv**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificando o caminho do arquivo CSV de destino\n",
    "caminho_arquivo_csv = './Files/Dataset_tratado/df_order_reviews'\n",
    "\n",
    "# Exportando o DataFrame para um arquivo CSV\n",
    "df_order_reviews.to_csv(caminho_arquivo_csv, index=False)\n",
    "\n",
    "# Imprimindo mensagem de confirmação\n",
    "print(f'O DataFrame foi exportado com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finalização**\n",
    "\n",
    "* Aqui finaliza a parte de limpeza e tratamento de dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
